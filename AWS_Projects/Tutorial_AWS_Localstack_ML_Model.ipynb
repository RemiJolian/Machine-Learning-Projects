{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Deploying a simple ML model on AWS services locally using LocalStack**"
      ],
      "metadata": {
        "id": "bTME2PuvKKrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here’s a step-by-step guide for deploying a dummy machine learning model using LocalStack on Windows. This procedure allows you to simulate an AWS environment locally, without needing an AWS account."
      ],
      "metadata": {
        "id": "QEb4kjyyAVLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "0gkRP6sU0fIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIEkeZ66aGX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install Prerequisites\n",
        "\n",
        "1. **Install Docker Desktop**\n",
        "\n",
        "   LocalStack relies on Docker to run services locally.\n",
        "   - Download Docker Desktop from the [official website](https://www.docker.com/products/docker-desktop/) and install it.\n",
        "   - After installation, open Docker Desktop and ensure it’s running."
      ],
      "metadata": {
        "id": "EZMyghqyBOxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Install Python (if not already installed)**\n",
        "   - Download Python from the [official Python website](https://www.python.org/downloads/).\n",
        "   - Ensure that you check the box to \"Add Python to PATH\" during installation.\n",
        "   - Verify installation by running:"
      ],
      "metadata": {
        "id": "syMXq6F8BePm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     python --version\n"
      ],
      "metadata": {
        "id": "rb09D0RdBlTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Install the AWS CLI**\n",
        "   - Download the AWS CLI version 2 installer from the [AWS CLI official website](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-windows.html).\n",
        "   - Run the installer, and ensure that the AWS CLI is added to your PATH.\n",
        "   - Verify installation by running:"
      ],
      "metadata": {
        "id": "3N8TDTHGBxP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " aws.exe --version"
      ],
      "metadata": {
        "id": "mInrjDG2B1KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Install LocalStack CLI**\n",
        "   - Install LocalStack using `pip`:"
      ],
      "metadata": {
        "id": "kto-aHsRCauL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install localstack\n"
      ],
      "metadata": {
        "id": "8-pEy4ZaCll-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Verify installation by running:\n",
        "    "
      ],
      "metadata": {
        "id": "DGI2XJ46Co6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "localstack --version"
      ],
      "metadata": {
        "id": "fWjerovrCq1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Configure LocalStack\n",
        "\n",
        "1. **Start LocalStack**\n",
        "   - Open a Command Prompt or PowerShell and start LocalStack:"
      ],
      "metadata": {
        "id": "-8EdB1tIDCM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "localstack start"
      ],
      "metadata": {
        "id": "UbxKY-ieDG34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - This will start LocalStack with all default services enabled (including S3, Lambda, etc.)."
      ],
      "metadata": {
        "id": "bPOxia19DLfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Configure AWS CLI to Work with LocalStack**\n",
        "   - Set up the AWS CLI with test credentials (LocalStack doesn't validate them):"
      ],
      "metadata": {
        "id": "z88jGI35DUho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws.exe configure set aws_access_key_id test\n",
        "aws.exe configure set aws_secret_access_key test\n",
        "aws.exe configure set default.region us-east-1"
      ],
      "metadata": {
        "id": "Xz3HaMt0DZKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mm2l0xS5SPzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Prepare a Dummy Model\n",
        "\n",
        "1. **Create a Dummy Model File**\n",
        "   - For this example, we’ll create a simple Python script(using Iris Dataset) to train a dummy model and save it using `pickle`.\n",
        "   - Create a new file named `train_model.py` with the following content:"
      ],
      "metadata": {
        "id": "gmBgD_ZGDoGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train.model.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Get the directory of the current script\n",
        "script_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "# File path for the output file in the same directory\n",
        "output_file_path = os.path.join(script_dir, 'model.pkl')\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris[\"data\"], iris[\"target\"]\n",
        "\n",
        "# Train model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Save the model\n",
        "with open(output_file_path, 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "print(f\"Model trained and saved as {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "PG4lOnUOD-NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Run the script to generate `model.pkl`:"
      ],
      "metadata": {
        "id": "mhV7htF9EiAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python train_model.py"
      ],
      "metadata": {
        "id": "taiLA0xhElgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 4: Upload the Model to S3 in LocalStack\n",
        "\n",
        "1. **Create an S3 Bucket**\n",
        "   - Use the AWS CLI to create a bucket in LocalStack:"
      ],
      "metadata": {
        "id": "tplJiSPQEs-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws.exe --endpoint-url=http://localhost:4566 s3 mb s3://my-test-bucket"
      ],
      "metadata": {
        "id": "8Gc29V-4EyjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Upload the Model File to the S3 Bucket**\n",
        "   - Upload `model.pkl` to the S3 bucket:"
      ],
      "metadata": {
        "id": "3OaWOWjLE3MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " aws.exe --endpoint-url=http://localhost:4566 s3 cp model.pkl s3://my-test-bucket/model.pkl"
      ],
      "metadata": {
        "id": "2dAtMtjoFoyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Deploy a Lambda Function\n",
        "\n",
        "1. **Create a Simple Lambda Function**\n",
        "   - Create a new file named `lambda_function.py` with the following content:"
      ],
      "metadata": {
        "id": "7M_BpNFhFCyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "import boto3\n",
        "\n",
        "\n",
        "# Configure the S3 client to use the LocalStack endpoint\n",
        "s3 = boto3.client('s3', endpoint_url='http://host.docker.internal:4566')\n",
        "# s3 = boto3.client('s3', endpoint_url='http://localhost:4566')\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    try:\n",
        "        print(\"Attempting to access S3\")\n",
        "        response = s3.get_object(Bucket='my-test-bucket', Key='model.pkl')\n",
        "        print(\"File accessed successfully\")\n",
        "        model_data = response['Body'].read()\n",
        "\n",
        "        model = pickle.loads(model_data)\n",
        "\n",
        "        return {\n",
        "            'statusCode': 200,\n",
        "            'body': json.dumps('Model loaded successfully')\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return {\n",
        "            'statusCode': 500,\n",
        "            'body': json.dumps(f\"Error: {str(e)}\")\n",
        "        }"
      ],
      "metadata": {
        "id": "JNs6SAwfE91Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Package the Lambda Function**\n",
        "   - Zip the `lambda_function.py` file to create a deployment package:"
      ],
      "metadata": {
        "id": "g5vEYrMyGM8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"C:\\Program Files\\7-Zip\\7z.exe\" a lambda_function.zip lambda_function.py"
      ],
      "metadata": {
        "id": "Wko4P72jGVdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Create the Lambda Function in LocalStack**\n",
        "   - Use the AWS CLI to create a Lambda function:"
      ],
      "metadata": {
        "id": "13GVbPdbGbun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws.exe --endpoint-url=http://localhost:4566 lambda create-function --function-name my-lambda-function --runtime python3.9 --handler lambda_function.lambda_handler --zip-file fileb://lambda_function.zip --role arn:aws:iam::000000000000:role/execution_role"
      ],
      "metadata": {
        "id": "Ldb-wNZkGg-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 6: Invoke the Lambda Function\n",
        "\n",
        "1. **Invoke the Lambda Function**\n",
        "   - Use the AWS CLI to test the Lambda function:"
      ],
      "metadata": {
        "id": "l3Yp61OgGwu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws.exe --endpoint-url=http://localhost:4566 lambda invoke --function-name lambdafunction output.json"
      ],
      "metadata": {
        "id": "95gRE8U7G2TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Check the `output.json` file for the result of the prediction in your current directory."
      ],
      "metadata": {
        "id": "m-NIH8UPG7B7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Clean Up (Optional)\n",
        "\n",
        "1. **Stop LocalStack**\n",
        "   - You can stop LocalStack by pressing `Ctrl+C` in the terminal where it is running or using:"
      ],
      "metadata": {
        "id": "9Kgt5RndHAeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "     localstack stop"
      ],
      "metadata": {
        "id": "IR6ORLIIHFV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **Delete the Created Resources**\n",
        "   - You can use the AWS CLI commands to delete the S3 bucket and Lambda function if needed."
      ],
      "metadata": {
        "id": "rGqZy7YKHJX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comments:\n",
        "if needed to update the Lambda function(after some modifings) you can use:"
      ],
      "metadata": {
        "id": "bZAv59aWKPqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " aws.exe --endpoint-url=http://localhost:4566 lambda update-function-code --function-name my-lambda-function --zip-file fileb://lambda_function.zip"
      ],
      "metadata": {
        "id": "oQq3efrFKTzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## These steps should help you deploy a dummy model using LocalStack, simulating an AWS environment locally."
      ],
      "metadata": {
        "id": "NId_YVxCHfYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More explaination above code:\n",
        "\n",
        "\n",
        "### Step 1: Install Prerequisites (AWS CLI, Docker, LocalStack CLI)\n",
        "Before you start, you need to have certain tools installed on your local system. AWS CLI is used to interact with AWS services, Docker provides containerized environments for running applications like LocalStack, and the LocalStack CLI lets you manage LocalStack. These tools enable you to simulate an AWS environment on your local machine without needing an actual AWS account.\n",
        "\n",
        "### Step 2: Configure LocalStack (Start LocalStack, Configure AWS CLI)\n",
        "LocalStack is a local AWS cloud service emulator. Once you start LocalStack, you need to configure your AWS CLI to communicate with it. This involves setting the endpoint URLs for various AWS services (e.g., S3, Lambda) so that your AWS CLI commands interact with the LocalStack environment instead of the real AWS cloud.\n",
        "\n",
        "### Step 3: Prepare a Dummy Model (Create a Dummy Model File)\n",
        "The dummy model file represents a simple version of a machine learning model or any other data file that your Lambda function will use. Since it's a dummy model, it doesn’t perform any complex computations; it can be just a text or JSON file containing basic data or simple algorithms to mimic a real model’s structure.\n",
        "\n",
        "### Step 4: Upload the Model to S3 in LocalStack (Create an S3 Bucket, Upload the Model File)\n",
        "To make the dummy model accessible, you create a storage space (bucket) in the LocalStack-simulated S3 service and upload the model file to it. This step mimics storing a model in an actual S3 bucket in AWS, allowing your Lambda function to access the file during execution.\n",
        "\n",
        "### Step 5: Deploy a Lambda Function (Create a Simple Lambda Function, Package the Lambda Function, Create the Lambda Function in LocalStack)\n",
        "You need to write a simple Lambda function that can, for example, read the dummy model file from the S3 bucket. The function code is then packaged for deployment. Finally, you create the Lambda function in the LocalStack environment, which simulates the behavior of AWS Lambda.\n",
        "\n",
        "AWS Lambda is a serverless compute service provided by AWS that allows you to run code in response to specific events without provisioning or managing servers. It automatically scales your application by running code in parallel in response to triggers such as request to an API endpoint, HTTP requests, file uploads to S3, or database changes. You pay only for the compute time used, making it cost-effective for various applications.\n",
        "\n",
        "In the context of deploying the dummy model, the Lambda function may be designed to load the model from an S3 bucket and perform basic operations, like returning a simple response or processing input data based on the model.\n",
        "\n",
        "### Step 6: Invoke the Lambda Function\n",
        "Once the Lambda function is deployed, you can trigger it using the AWS CLI or LocalStack CLI. This invocation allows you to test whether the Lambda function executes as expected in the LocalStack environment, using the model file stored in the simulated S3 service.\n",
        "\n",
        "### Step 7: Clean Up (Stop LocalStack, Delete the Created Resources)\n",
        "After testing, you should clean up by stopping LocalStack and deleting the created resources (e.g., the S3 bucket, the Lambda function). This helps free up system resources and prevents conflicts or issues if you need to run LocalStack again for another project.\n",
        "\n",
        "# **These steps help replicate the process of deploying a machine learning model and serverless functions in a real AWS environment, all within your local development setup.**"
      ],
      "metadata": {
        "id": "4U-ZrkNlH0DV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkuXNILE0gGp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}